{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a869519f",
   "metadata": {},
   "source": [
    "## Loading the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32bf09fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "#import mlflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d9342d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14034 3509 3096\n",
      "..\\data\\raw\\PlantVillage\\YellowLeaf__Curl_Virus\\60d14bc3-b703-4b83-8bf9-f13124970145___YLCV_GCREC 2934.JPG 7\n"
     ]
    }
   ],
   "source": [
    "# loading the data splits\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "split_dir = Path(\"../data/splits\")\n",
    "\n",
    "train_paths  = np.load(split_dir / \"train_paths.npy\", allow_pickle=True)\n",
    "train_labels = np.load(split_dir / \"train_labels.npy\", allow_pickle=True)\n",
    "\n",
    "val_paths  = np.load(split_dir / \"val_paths.npy\", allow_pickle=True)\n",
    "val_labels = np.load(split_dir / \"val_labels.npy\", allow_pickle=True)\n",
    "\n",
    "test_paths  = np.load(split_dir / \"test_paths.npy\", allow_pickle=True)\n",
    "test_labels = np.load(split_dir / \"test_labels.npy\", allow_pickle=True)\n",
    "\n",
    "print(len(train_paths), len(val_paths), len(test_paths))\n",
    "print(train_paths[0], train_labels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bafe39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Bacterial_spot\n",
      "1: Early_blight\n",
      "2: Late_blight\n",
      "3: Leaf_Mold\n",
      "4: Septoria_leaf_spot\n",
      "5: Spider_mites_Two_spotted_spider_mite\n",
      "6: Target_Spot\n",
      "7: YellowLeaf__Curl_Virus\n",
      "8: healthy\n",
      "9: mosaic_virus\n"
     ]
    }
   ],
   "source": [
    "#Loading the class names\n",
    "\n",
    "import json\n",
    "\n",
    "with open(split_dir / \"class_names.json\", \"r\") as f:\n",
    "    class_names = json.load(f)\n",
    "\n",
    "for i, name in enumerate(class_names):\n",
    "    print(f\"{i}: {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811aef69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3) (32,) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Build TensorFlow datasets from the indices\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE = (224, 224) #for EfficientNetB0\n",
    "BATCH_SIZE = 32\n",
    "SEED = 12\n",
    "\n",
    "def load_image(path, label):\n",
    "    img = tf.io.read_file(path) #reads the image file\n",
    "    img = tf.image.decode_image(img, channels=3, expand_animations=False) #decodes images into uint8 tensor, RGB channels\n",
    "    img = tf.image.resize(img, IMG_SIZE) #resizes images to specified size\n",
    "    img = tf.cast(img, tf.float32)  # keep [0..255]\n",
    "    img.set_shape([IMG_SIZE[0], IMG_SIZE[1], 3]) # forces static shape of the tensor\n",
    "    return img, label #returns image and label in a format suitable for Keras\n",
    "\n",
    "def make_dataset(paths, labels, shuffle=False):\n",
    "    paths = np.array([str(p) for p in paths])  # convert WindowsPath -> str\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels)) #creates a dataset where each element is (path, label)\n",
    "    ds = ds.map(load_image, num_parallel_calls=tf.data.AUTOTUNE) #each element is processed by load_image function\n",
    "    ds = ds.ignore_errors() #ignores errors during data loading\n",
    "    if shuffle: # shuffle is for training dataset only, prevents from seeing the data in the same order every epoch\n",
    "        ds = ds.shuffle(2000, seed=SEED, reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE) #groups samples into batches and fetches them in the background\n",
    "    return ds\n",
    "\n",
    "\n",
    "pv_train_ds = make_dataset(train_paths, train_labels, shuffle=True)\n",
    "pv_val_ds   = make_dataset(val_paths, val_labels)\n",
    "pv_test_ds  = make_dataset(test_paths, test_labels)\n",
    "\n",
    "x, y = next(iter(pv_train_ds))\n",
    "print(x.shape, y.shape, x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97440552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('../data/raw/PlantVillage/YellowLeaf__Curl_Virus/60d14bc3-b703-4b83-8bf9-f13124970145___YLCV_GCREC 2934.JPG')\n",
      " WindowsPath('../data/raw/PlantVillage/Late_blight/3c20c90a-788c-4d06-acdb-107f695d901b___RS_LB 4856.JPG')\n",
      " WindowsPath('../data/raw/PlantVillage/YellowLeaf__Curl_Virus/172cb996-a7ad-45a3-9d3b-0be425414d94___YLCV_GCREC 2323.JPG')]\n"
     ]
    }
   ],
   "source": [
    "print(train_paths[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad9c711",
   "metadata": {},
   "source": [
    "Now we add the wild train/val data. Wild test data is already stored in ..data/wild_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fa987d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "split_dir = Path(\"../data/splits\")\n",
    "\n",
    "wild_train_paths  = np.load(split_dir / \"wild_train_paths.npy\", allow_pickle=True)\n",
    "wild_train_labels = np.load(split_dir / \"wild_train_labels.npy\")\n",
    "\n",
    "wild_val_paths  = np.load(split_dir / \"wild_val_paths.npy\", allow_pickle=True)\n",
    "wild_val_labels = np.load(split_dir / \"wild_val_labels.npy\")\n",
    "\n",
    "wild_train_ds = make_dataset(wild_train_paths, wild_train_labels, shuffle=True)\n",
    "wild_val_ds   = make_dataset(wild_val_paths, wild_val_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824e56da",
   "metadata": {},
   "source": [
    "We create a mixed train dataset from the original and wild dataset. Same goes for validation dataset. In both cases, the wild data is strongly weighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7097f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_train_ds = tf.data.Dataset.sample_from_datasets(\n",
    "    [pv_train_ds, wild_train_ds],\n",
    "    weights=[0.3, 0.7],\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_ds = tf.data.Dataset.sample_from_datasets(\n",
    "    [pv_val_ds, wild_val_ds],\n",
    "    weights=[0.3, 0.7],\n",
    "    seed=SEED\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e88288a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3) (32,) <dtype: 'float32'> <dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(mixed_train_ds))\n",
    "print(x.shape, y.shape, x.dtype, y.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a75611",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60594997",
   "metadata": {},
   "source": [
    "1) Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60c7958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.06),\n",
    "    tf.keras.layers.RandomZoom(0.15),\n",
    "    tf.keras.layers.RandomTranslation(0.08, 0.08),\n",
    "    tf.keras.layers.RandomContrast(0.25),\n",
    "    tf.keras.layers.RandomBrightness(0.20),\n",
    "    tf.keras.layers.GaussianNoise(0.03),\n",
    "], name=\"augmentation\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8454d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to deal with hand occlusions, etc.\n",
    "# layers.RandomErasing = getattr(layers, \"RandomErasing\", None)\n",
    "#if layers.RandomErasing is not None:\n",
    "#    data_augmentation.add(layers.RandomErasing(factor=0.15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1fdb88",
   "metadata": {},
   "source": [
    "2) EfficientNet preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b78d114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing layer for EfficientNet\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "preprocess = layers.Lambda(preprocess_input, name=\"preprocess_input\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5c9733",
   "metadata": {},
   "source": [
    "3) Build the model (EfficientNetB0 default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9da7eb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " augmentation (Sequential)   (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " preprocess_input (Lambda)   (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " efficientnetb0 (Functional  (None, 1280)              4049571   \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                12810     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4062381 (15.50 MB)\n",
      "Trainable params: 12810 (50.04 KB)\n",
      "Non-trainable params: 4049571 (15.45 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "\n",
    "NUM_CLASSES = len(class_names)\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "base_model = tf.keras.applications.EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(*IMG_SIZE, 3),\n",
    "    pooling=\"avg\"\n",
    ")\n",
    "base_model.trainable = False  # phase 1: freeze backbone\n",
    "\n",
    "\n",
    "inputs = layers.Input(shape=(*IMG_SIZE, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess(x)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5987f28",
   "metadata": {},
   "source": [
    "4) Compile + callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74153916",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "848d5bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"../models/v3_best.keras\", monitor=\"val_loss\", mode=\"min\", save_best_only=True),\n",
    "    EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", mode=\"min\", factor=0.5, patience=2, min_lr=1e-6, verbose=1),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbcf8e0",
   "metadata": {},
   "source": [
    "5) Train phase 1 (with frozen backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7429b901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "444/444 [==============================] - 276s 606ms/step - loss: 1.0273 - accuracy: 0.6923 - val_loss: 0.6315 - val_accuracy: 0.8188 - lr: 0.0010\n",
      "Epoch 2/8\n",
      "444/444 [==============================] - 264s 594ms/step - loss: 0.6177 - accuracy: 0.8158 - val_loss: 0.4853 - val_accuracy: 0.8524 - lr: 0.0010\n",
      "Epoch 3/8\n",
      "444/444 [==============================] - 261s 587ms/step - loss: 0.5165 - accuracy: 0.8457 - val_loss: 0.4435 - val_accuracy: 0.8575 - lr: 0.0010\n",
      "Epoch 4/8\n",
      "444/444 [==============================] - 259s 583ms/step - loss: 0.4676 - accuracy: 0.8572 - val_loss: 0.3996 - val_accuracy: 0.8710 - lr: 0.0010\n",
      "Epoch 5/8\n",
      "444/444 [==============================] - 263s 590ms/step - loss: 0.4387 - accuracy: 0.8648 - val_loss: 0.3730 - val_accuracy: 0.8789 - lr: 0.0010\n",
      "Epoch 6/8\n",
      "444/444 [==============================] - 260s 584ms/step - loss: 0.4054 - accuracy: 0.8725 - val_loss: 0.3432 - val_accuracy: 0.8888 - lr: 0.0010\n",
      "Epoch 7/8\n",
      "444/444 [==============================] - 261s 587ms/step - loss: 0.3984 - accuracy: 0.8757 - val_loss: 0.3213 - val_accuracy: 0.9015 - lr: 0.0010\n",
      "Epoch 8/8\n",
      "444/444 [==============================] - 259s 582ms/step - loss: 0.3800 - accuracy: 0.8805 - val_loss: 0.3371 - val_accuracy: 0.8857 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit(\n",
    "    mixed_train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=8,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6cd983",
   "metadata": {},
   "source": [
    "## Phase 2, fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40be8884",
   "metadata": {},
   "source": [
    "1) Load the best phase-1 weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "902f7268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ../models/v3_best.keras\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model(\"../models/v3_best.keras\", safe_mode=False)\n",
    "print(\"Loaded:\", \"../models/v3_best.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6f6e15",
   "metadata": {},
   "source": [
    "2) Unfreeze the backbone partially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cf07abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model: efficientnetb0\n",
      "Trainable layers in base_model: 80 / 239\n"
     ]
    }
   ],
   "source": [
    "# Find the base model by name (we created it as EfficientNetB0)\n",
    "base_model = None\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, tf.keras.Model) and \"efficientnet\" in layer.name.lower():\n",
    "        base_model = layer\n",
    "        break\n",
    "\n",
    "print(\"Base model:\", base_model.name)\n",
    "\n",
    "base_model.trainable = True\n",
    "\n",
    "# Unfreeze only top N layers (start with 20)\n",
    "N = 80\n",
    "for layer in base_model.layers[:-N]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(\"Trainable layers in base_model:\", sum(l.trainable for l in base_model.layers), \"/\", len(base_model.layers))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755be697",
   "metadata": {},
   "source": [
    "3) Recompile with a very small learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2c3de02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20af763e",
   "metadata": {},
   "source": [
    "4) Training, fine-tune for a few epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e6a4840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "444/444 [==============================] - 373s 818ms/step - loss: 0.3143 - accuracy: 0.8983 - val_loss: 0.2519 - val_accuracy: 0.9190 - lr: 1.0000e-05\n",
      "Epoch 2/10\n",
      "444/444 [==============================] - 368s 828ms/step - loss: 0.2565 - accuracy: 0.9160 - val_loss: 0.2139 - val_accuracy: 0.9323 - lr: 1.0000e-05\n",
      "Epoch 3/10\n",
      "444/444 [==============================] - 372s 836ms/step - loss: 0.2152 - accuracy: 0.9308 - val_loss: 0.1908 - val_accuracy: 0.9376 - lr: 1.0000e-05\n",
      "Epoch 4/10\n",
      "444/444 [==============================] - 369s 829ms/step - loss: 0.1848 - accuracy: 0.9383 - val_loss: 0.1705 - val_accuracy: 0.9464 - lr: 1.0000e-05\n",
      "Epoch 5/10\n",
      "444/444 [==============================] - 382s 858ms/step - loss: 0.1669 - accuracy: 0.9455 - val_loss: 0.1568 - val_accuracy: 0.9498 - lr: 1.0000e-05\n",
      "Epoch 6/10\n",
      "444/444 [==============================] - 373s 840ms/step - loss: 0.1461 - accuracy: 0.9527 - val_loss: 0.1584 - val_accuracy: 0.9486 - lr: 1.0000e-05\n",
      "Epoch 7/10\n",
      "444/444 [==============================] - 365s 821ms/step - loss: 0.1326 - accuracy: 0.9567 - val_loss: 0.1344 - val_accuracy: 0.9599 - lr: 1.0000e-05\n",
      "Epoch 8/10\n",
      "444/444 [==============================] - 367s 826ms/step - loss: 0.1212 - accuracy: 0.9599 - val_loss: 0.1324 - val_accuracy: 0.9596 - lr: 1.0000e-05\n",
      "Epoch 9/10\n",
      "444/444 [==============================] - 367s 825ms/step - loss: 0.1128 - accuracy: 0.9639 - val_loss: 0.1207 - val_accuracy: 0.9650 - lr: 1.0000e-05\n",
      "Epoch 10/10\n",
      "444/444 [==============================] - 365s 821ms/step - loss: 0.1004 - accuracy: 0.9676 - val_loss: 0.1140 - val_accuracy: 0.9658 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(\n",
    "    mixed_train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a7a3e0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e4444cd",
   "metadata": {},
   "source": [
    "To control whether all image files are ok:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a957cdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PV train: 0 zero-byte/unreadable files\n",
      "Wild train: 0 zero-byte/unreadable files\n",
      "Wild val: 0 zero-byte/unreadable files\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def find_zero_byte(paths, name):\n",
    "    bad = []\n",
    "    for p in paths:\n",
    "        p = Path(p)\n",
    "        try:\n",
    "            if p.exists() and p.stat().st_size == 0:\n",
    "                bad.append(str(p))\n",
    "        except OSError:\n",
    "            bad.append(str(p))\n",
    "    print(f\"{name}: {len(bad)} zero-byte/unreadable files\")\n",
    "    for b in bad[:20]:\n",
    "        print(\"  \", b)\n",
    "    return bad\n",
    "\n",
    "bad_pv = find_zero_byte(train_paths, \"PV train\")\n",
    "bad_wt = find_zero_byte(wild_train_paths, \"Wild train\")\n",
    "bad_wv = find_zero_byte(wild_val_paths, \"Wild val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "930c81d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[wild_val] No bad files found.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "def find_first_bad(paths, name=\"set\"):\n",
    "    for p in paths:\n",
    "        p = Path(p)\n",
    "        try:\n",
    "            raw = tf.io.read_file(str(p))\n",
    "            # Force eager conversion so errors surface here\n",
    "            raw_bytes = raw.numpy()\n",
    "            if len(raw_bytes) == 0:\n",
    "                print(f\"[{name}] EMPTY READ:\", p)\n",
    "                return str(p)\n",
    "            img = tf.image.decode_image(raw, channels=3, expand_animations=False)\n",
    "            _ = img.numpy()  # force decode\n",
    "        except Exception as e:\n",
    "            print(f\"[{name}] BAD FILE:\", p)\n",
    "            print(\"Reason:\", repr(e))\n",
    "            return str(p)\n",
    "    print(f\"[{name}] No bad files found.\")\n",
    "    return None\n",
    "\n",
    "# bad = find_first_bad(wild_train_paths, \"wild_train\")\n",
    "# If none found, try mixed sources:\n",
    "# bad = find_first_bad(train_paths, \"pv_train\")\n",
    "bad = find_first_bad(wild_val_paths, \"wild_val\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
