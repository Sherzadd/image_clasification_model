{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a869519f",
   "metadata": {},
   "source": [
    "## Loading the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32bf09fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ogina\\Desktop\\DS_Bootcamp\\Capstone_Project\\image_clasification_model\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "#import mlflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d9342d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14034 3509 3096\n",
      "..\\data\\raw\\PlantVillage\\YellowLeaf__Curl_Virus\\60d14bc3-b703-4b83-8bf9-f13124970145___YLCV_GCREC 2934.JPG 7\n"
     ]
    }
   ],
   "source": [
    "# loading the data splits\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "split_dir = Path(\"../data/splits\")\n",
    "\n",
    "train_paths  = np.load(split_dir / \"train_paths.npy\", allow_pickle=True)\n",
    "train_labels = np.load(split_dir / \"train_labels.npy\", allow_pickle=True)\n",
    "\n",
    "val_paths  = np.load(split_dir / \"val_paths.npy\", allow_pickle=True)\n",
    "val_labels = np.load(split_dir / \"val_labels.npy\", allow_pickle=True)\n",
    "\n",
    "test_paths  = np.load(split_dir / \"test_paths.npy\", allow_pickle=True)\n",
    "test_labels = np.load(split_dir / \"test_labels.npy\", allow_pickle=True)\n",
    "\n",
    "print(len(train_paths), len(val_paths), len(test_paths))\n",
    "print(train_paths[0], train_labels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bafe39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Bacterial_spot\n",
      "1: Early_blight\n",
      "2: Late_blight\n",
      "3: Leaf_Mold\n",
      "4: Septoria_leaf_spot\n",
      "5: Spider_mites_Two_spotted_spider_mite\n",
      "6: Target_Spot\n",
      "7: YellowLeaf__Curl_Virus\n",
      "8: healthy\n",
      "9: mosaic_virus\n"
     ]
    }
   ],
   "source": [
    "#Loading the class names\n",
    "\n",
    "import json\n",
    "\n",
    "with open(split_dir / \"class_names.json\", \"r\") as f:\n",
    "    class_names = json.load(f)\n",
    "\n",
    "for i, name in enumerate(class_names):\n",
    "    print(f\"{i}: {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "811aef69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3) (32,) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Build TensorFlow datasets from the indices\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE = (224, 224) #for EfficientNetB0\n",
    "BATCH_SIZE = 32\n",
    "SEED = 12\n",
    "\n",
    "def load_image(path, label):\n",
    "    img = tf.io.read_file(path) #reads the image file\n",
    "    img = tf.image.decode_image(img, channels=3, expand_animations=False) #decodes JPEG images into uint8 tensor, RGB channels\n",
    "    img = tf.image.resize(img, IMG_SIZE) #resizes images to specified size\n",
    "    img = tf.cast(img, tf.float32)  # keep [0..255]\n",
    "    return img, label #returns image and label in a format suitable for Keras\n",
    "\n",
    "def make_dataset(paths, labels, shuffle=False):\n",
    "    paths = np.array([str(p) for p in paths])  # convert WindowsPath -> str\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels)) #creates a dataset where each element is (path, label)\n",
    "    ds = ds.map(load_image, num_parallel_calls=tf.data.AUTOTUNE) #each element is processed by load_image function\n",
    "    ds = ds.ignore_errors() #ignores errors during data loading\n",
    "    if shuffle: # shuffle is for training dataset only, prevents from seeing the data in the same order every epoch\n",
    "        ds = ds.shuffle(2000, seed=SEED, reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE) #groups samples into batches and fetches them in the background\n",
    "    return ds\n",
    "\n",
    "\n",
    "pv_train_ds = make_dataset(train_paths, train_labels, shuffle=True)\n",
    "pv_val_ds   = make_dataset(val_paths, val_labels)\n",
    "pv_test_ds  = make_dataset(test_paths, test_labels)\n",
    "\n",
    "x, y = next(iter(pv_train_ds))\n",
    "print(x.shape, y.shape, x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97440552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('../data/raw/PlantVillage/YellowLeaf__Curl_Virus/60d14bc3-b703-4b83-8bf9-f13124970145___YLCV_GCREC 2934.JPG')\n",
      " WindowsPath('../data/raw/PlantVillage/Late_blight/3c20c90a-788c-4d06-acdb-107f695d901b___RS_LB 4856.JPG')\n",
      " WindowsPath('../data/raw/PlantVillage/YellowLeaf__Curl_Virus/172cb996-a7ad-45a3-9d3b-0be425414d94___YLCV_GCREC 2323.JPG')]\n"
     ]
    }
   ],
   "source": [
    "print(train_paths[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad9c711",
   "metadata": {},
   "source": [
    "Now we add the wild train/val data. Wild test data is already stored in ..data/wild_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fa987d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "split_dir = Path(\"../data/splits\")\n",
    "\n",
    "wild_train_paths  = np.load(split_dir / \"wild_train_paths.npy\", allow_pickle=True)\n",
    "wild_train_labels = np.load(split_dir / \"wild_train_labels.npy\")\n",
    "\n",
    "wild_val_paths  = np.load(split_dir / \"wild_val_paths.npy\", allow_pickle=True)\n",
    "wild_val_labels = np.load(split_dir / \"wild_val_labels.npy\")\n",
    "\n",
    "wild_train_ds = make_dataset(wild_train_paths, wild_train_labels, shuffle=True)\n",
    "wild_val_ds   = make_dataset(wild_val_paths, wild_val_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824e56da",
   "metadata": {},
   "source": [
    "We create a mixed train dataset from the original and wild dataset. Same goes for validation dataset. In both cases, the wild data is strongly weighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7097f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_train_ds = tf.data.Dataset.sample_from_datasets(\n",
    "    [pv_train_ds, wild_train_ds],\n",
    "    weights=[0.7, 0.3],\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_ds = tf.data.Dataset.sample_from_datasets(\n",
    "    [wild_val_ds, pv_val_ds],\n",
    "    weights=[0.7, 0.3],\n",
    "    seed=SEED\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e88288a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3) (32,) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(mixed_train_ds))\n",
    "print(x.shape, y.shape, x.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a75611",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60594997",
   "metadata": {},
   "source": [
    "1) Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60c7958e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ogina\\Desktop\\DS_Bootcamp\\Capstone_Project\\image_clasification_model\\.venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.15),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomTranslation(0.1, 0.1),\n",
    "    layers.RandomContrast(0.2),\n",
    "], name=\"augmentation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af8454d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to deal with hand occlusions, etc.\n",
    "layers.RandomErasing = getattr(layers, \"RandomErasing\", None)\n",
    "if layers.RandomErasing is not None:\n",
    "    data_augmentation.add(layers.RandomErasing(factor=0.15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1fdb88",
   "metadata": {},
   "source": [
    "2) EfficientNet preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b78d114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing layer for EfficientNet\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "preprocess = layers.Lambda(preprocess_input, name=\"preprocess_input\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5c9733",
   "metadata": {},
   "source": [
    "3) Build v2 model (EfficientNetB0 default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9da7eb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ogina\\Desktop\\DS_Bootcamp\\Capstone_Project\\image_clasification_model\\.venv\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " augmentation (Sequential)   (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " preprocess_input (Lambda)   (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " efficientnetb0 (Functional  (None, 1280)              4049571   \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                12810     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4062381 (15.50 MB)\n",
      "Trainable params: 12810 (50.04 KB)\n",
      "Non-trainable params: 4049571 (15.45 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "\n",
    "NUM_CLASSES = len(class_names)\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "base_model = tf.keras.applications.EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(*IMG_SIZE, 3),\n",
    "    pooling=\"avg\"\n",
    ")\n",
    "base_model.trainable = False  # phase 1: freeze backbone\n",
    "\n",
    "inputs = layers.Input(shape=(*IMG_SIZE, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess(x)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5987f28",
   "metadata": {},
   "source": [
    "4) Compile + callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74153916",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "848d5bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"../models/v2_best.keras\", monitor=\"val_loss\", mode=\"min\", save_best_only=True),\n",
    "    EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", mode=\"min\", factor=0.5, patience=2, min_lr=1e-6, verbose=1),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbcf8e0",
   "metadata": {},
   "source": [
    "5) Train phase 1 (with frozen backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7429b901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:From c:\\Users\\ogina\\Desktop\\DS_Bootcamp\\Capstone_Project\\image_clasification_model\\.venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ogina\\Desktop\\DS_Bootcamp\\Capstone_Project\\image_clasification_model\\.venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "445/445 [==============================] - 257s 563ms/step - loss: 1.0645 - accuracy: 0.6728 - val_loss: 0.7294 - val_accuracy: 0.7682 - lr: 0.0010\n",
      "Epoch 2/2\n",
      "445/445 [==============================] - 255s 571ms/step - loss: 0.6490 - accuracy: 0.8037 - val_loss: 0.5541 - val_accuracy: 0.8295 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit(\n",
    "    mixed_train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=2,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a957cdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PV train: 0 zero-byte/unreadable files\n",
      "Wild train: 0 zero-byte/unreadable files\n",
      "Wild val: 0 zero-byte/unreadable files\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def find_zero_byte(paths, name):\n",
    "    bad = []\n",
    "    for p in paths:\n",
    "        p = Path(p)\n",
    "        try:\n",
    "            if p.exists() and p.stat().st_size == 0:\n",
    "                bad.append(str(p))\n",
    "        except OSError:\n",
    "            bad.append(str(p))\n",
    "    print(f\"{name}: {len(bad)} zero-byte/unreadable files\")\n",
    "    for b in bad[:20]:\n",
    "        print(\"  \", b)\n",
    "    return bad\n",
    "\n",
    "bad_pv = find_zero_byte(train_paths, \"PV train\")\n",
    "bad_wt = find_zero_byte(wild_train_paths, \"Wild train\")\n",
    "bad_wv = find_zero_byte(wild_val_paths, \"Wild val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "930c81d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[wild_val] No bad files found.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "def find_first_bad(paths, name=\"set\"):\n",
    "    for p in paths:\n",
    "        p = Path(p)\n",
    "        try:\n",
    "            raw = tf.io.read_file(str(p))\n",
    "            # Force eager conversion so errors surface here\n",
    "            raw_bytes = raw.numpy()\n",
    "            if len(raw_bytes) == 0:\n",
    "                print(f\"[{name}] EMPTY READ:\", p)\n",
    "                return str(p)\n",
    "            img = tf.image.decode_image(raw, channels=3, expand_animations=False)\n",
    "            _ = img.numpy()  # force decode\n",
    "        except Exception as e:\n",
    "            print(f\"[{name}] BAD FILE:\", p)\n",
    "            print(\"Reason:\", repr(e))\n",
    "            return str(p)\n",
    "    print(f\"[{name}] No bad files found.\")\n",
    "    return None\n",
    "\n",
    "# bad = find_first_bad(wild_train_paths, \"wild_train\")\n",
    "# If none found, try mixed sources:\n",
    "# bad = find_first_bad(train_paths, \"pv_train\")\n",
    "bad = find_first_bad(wild_val_paths, \"wild_val\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
